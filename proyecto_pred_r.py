# -*- coding: utf-8 -*-
"""Proyecto_Pred_R.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pTOULcCHclN667MGIH0Gxa-1Iv6vr7Zy

<center><H1><B>PROYECTO 1 PARCIAL - GRUPO # 1

<Center><img src= https://i.ytimg.com/vi/e9Dc-f2I9AY/maxresdefault.jpg width="800" height="380"></Center>

#**INFORMACIÓN**

### **Grupo#1**


*   Lady Siguencia
*   Jalmar Cedeño
*   Melanie Gavilanes
*   Dario Macias
*   Emilio Bletran

**TEMA:** Analisis Predictivo de ROE/ROA a través de indicadores financieros en las Empresas del Ecuador.

*   **AÑO - ENTRENAMIENTO:** 2019
*   **TABLA DE RESULTADOS - PREDICCIÓN:** 2017- 2018 - 2020
*   **CATEGORIAS**

DESCRIPCIÓN |RAMA 
--- | -------------- 
MINAS Y CANTERAS|B       
ARTES|R   
COMERCIO AL POR MAYOR|G 
AGRICULTURA |A     
ACTIVIDADES FINANCIERAS|K  
OTRAS ACTIVIDADES DE SERVICIOS |S  
SUMINISTRO DE ELECTRICIDAD|D   
ACTIVIDADES INMOBILIARIAS|L 
ENSEÑANZA. |P  
SERVICIOS ADMINISTRATIVOS|N   
COMUNICACION|J 
ACTIVIDADES PROFESIONALES|M  
SALUD HUMANA  |Q|
SERVICIO DE COMIDAS |I  
CONSTRUCCION |F  
INDUSTRIAS MANUFACTURERAS |C

### **INTRODUCCIÓN**

*  El análisis de regresión es una técnica estadística para estudiar la relación entre
variables.
*  Tanto en el caso de dos variables (regresión simple) como en el caso de más de dos
variables (regresión múltiple), el análisis puede utilizarse para explorar y cuantificar la
relación entre una variable llamada dependiente o criterio (Y) y una o más variables
llamadas independientes, predictoras o regresoras (X1, X2, …, Xn).
*  El objetivo de la regresión es
descubrir la relación funcional entre la entrada y la salida de este sistema, para poder
así predecir la salida del sistema cuando se le presenta un dato de entrada nuevo.

### **IMPORTACIONES**

**A traves de esta cuadro de codigo se busca establecer una amplia gama de algoritmos de aprendizaje profundo.**
"""

# Commented out IPython magic to ensure Python compatibility.
import torch
import numpy as np
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,  accuracy_score

"""**Establer conexión con nuestra cuenta de google drive para conectarnos con la parpeta donde se encuentran nuestros Datasets**"""

from google.colab import drive
drive.mount('/content/drive')

"""**Llamamos a muestro archivo xlsx, nuestro dataset con la ruta en donde esta ubicado**"""

#LLamar Datasets
df_indicadores2019 = pd.read_excel('/content/drive/My Drive/DataSets/indicadores2019_cia.xlsx')
df_indicadores2019 = df_indicadores2019[(df_indicadores2019['ROE']>-1) & (df_indicadores2019['ROE']<1) &(df_indicadores2019['ROA']>-1) & (df_indicadores2019['ROA']<1)]
df_indicadores2019

"""#**LIMPIEZA DE TABLAS**

**isnull** a traves de iteraciones nos permite contar las columnas, contando para cada columna cuántos valores nulos hay y producir un nuevo marco de datos que muestre la suma de los valores **(sum())** junto con los nombres de encabezado de columna.
"""

df_indicadores2019.isnull().sum()



df_indicadores2019.duplicated().any()
df_indicadores2019.dropna(inplace=True)
df_indicadores2019.shape

"""## **Información de Variables**"""

df_indicadores2019.isnull().any()

"""###**Columnas**

**Verificar las categorias de las columnas**
"""

df_indicadores2019.columns

"""###**Numero De Datos Fila**"""

len(df_indicadores2019)

df_indicadores2019['ROE'].describe()

df_indicadores2019['ROA'].describe()

"""#**Análisis Exploratorio**

**Este gráfico nos permite idenificar los valores del ROE para su posterior análisis**
"""

sns.distplot(df_indicadores2019['ROE'],color ='blue',bins=60)

"""**Este gráfico nos permite idenificar los valores del ROA para su posterior análisis**"""

sns.distplot(df_indicadores2019['ROA'],color ='red',bins=50)

df_indicadores2019[df_indicadores2019['ROE']<60].sample(600).plot.scatter(x='ROA', y='ENDEUDAMIENTO A CORTO PLAZO')

df_indicadores2019[df_indicadores2019['ROA']<60].sample(600).plot.scatter(x='ROA', y='APALANCAMIENTO FINANCIERO')

y = df_indicadores2019['LIQUIDEZ CORRIENTE'][:500]
plt.plot(y)
plt.show()

"""**En la siguente gráfica se busca establecer cuales son las varibles que estan relacionadas a razón del ROA y ROE**"""

dfs_corr = df_indicadores2019.drop(['AÑO','NOMBRE',	'EXPEDIENTE', 'RAMA', 'DESCRIPCIÓN RAMA','RAMA 6 DÍGITOS', 'SUBRAMA 2 DÍGITOS'], axis=1)
plt.figure(figsize=(50,40), facecolor='white')
plotnumber = 1

for column in dfs_corr.columns:
    if plotnumber<32 : ## 14 columns in data 
        plt.subplot(6,6,plotnumber)## 4 : rows , 4: columns , plotnumber : position of plot
        sns.distplot(dfs_corr[column])
        plt.xlabel(column,fontsize=20)
    plotnumber+=1
plt.show()

"""##**Selección Variables**"""

dfs_corr.corr()

"""## **MAPA DE CALOR**

**Objetivo:** representar los datos a través de un  gráfica, donde los valores individuales contenidos en una matriz se representan como colores. Este mapa de calor es perfectos para explorar la correlación de características en un conjunto de datos.
"""

plt.figure(figsize=(30,10))
sns.heatmap(dfs_corr.corr(),vmin=-1, vmax=1, annot=True, cmap="GnBu")

"""###**MAYOR CORRELACCIÓN ROE**
-- | Indicador ROE | Correlacción 
--- | -------------- | ---------- 
1.   |RENTABLIDAD FINANCIERA |1
2.   |RENTABILIDAD NETA DEL ACTIVO |0.7
3.   |UTILIDAD OPERACIONAL/TOTAL DE ACTIVOS |0.23
4.   |ROTACION DE VENTAS| 0.18
5.   |ENDEUDAMIENTO PATRIMONIAL CORRIENTE|0.041


###**MAYOR CORRELACCIÓN ROA**

-- | Indicador ROA | Correlacción 
--- | -------------- | ---------- 
1.   |RENTABILIDAD NETA DEL ACTIVO|1
2.   |RENTABLIDAD FINANCIERA |0.7
3.   |RENTABILIDAD NETA DE VENTAS|0.1
4.   |ENDEUDAMIENTO A CORTO PLAZO| 0.13
5.   |ROTACIÓN DE ACTIVO FIJO |0.023

#**Modelo De Regresión Lineal -- ROE**

**Objetivos**
*  Establecer muestras variables para el modelo de regresion lineal.
*  Establer un rango, donde se puedan eliminar los outlier, con el fin de utilizar datos mas relacionados y predecir mejor.
"""

dfs_rg_l =  df_indicadores2019[['ROE','DESCRIPCIÓN RAMA','RAMA','RENTABLIDAD FINANCIERA','RENTABILIDAD NETA DEL ACTIVO','UTILIDAD OPERACIONAL/TOTAL DE ACTIVOS ','ROTACIÓN DE VENTAS','ENDEUDAMIENTO PATRIMONIAL CORRIENTE']]
#Remover Outliers
dfs_rg_l = dfs_rg_l[(dfs_rg_l['ROE'] > -1) & (dfs_rg_l['ROE'] < 1) & (dfs_rg_l['RENTABLIDAD FINANCIERA'] < 100) & (dfs_rg_l['UTILIDAD OPERACIONAL/TOTAL DE ACTIVOS '] > -10) &
            (dfs_rg_l['RENTABILIDAD NETA DEL ACTIVO'] > -3) & (dfs_rg_l['ROTACIÓN DE VENTAS'] < 10) & (dfs_rg_l['ENDEUDAMIENTO PATRIMONIAL CORRIENTE'] < 400)]
dfs_rg_l

"""**Mostrar Datos de la Matriz ROA**"""

dfs_Y = dfs_rg_l[['ROE']]
dfs_Y

"""**Relacionamos las variables "X"**"""

dfs_X = dfs_rg_l[[ 'RENTABLIDAD FINANCIERA','RENTABILIDAD NETA DEL ACTIVO','UTILIDAD OPERACIONAL/TOTAL DE ACTIVOS ','ROTACIÓN DE VENTAS','ENDEUDAMIENTO PATRIMONIAL CORRIENTE']]
dfs_X

"""**Graficas de los valores y rango de las varibeles "X"**"""

dfs_X.plot(subplots=True, layout=(-1,3), figsize=(30,10) )

"""**Graficas de los valores y rango de las varibeles "Y / ROE"**"""

dfs_Y.plot(subplots=True, layout=(-1,3), figsize=(30,5) )

"""###**ENTRENAMIENTO**

*  La idea detrás de StandardScaler es que transformará sus datos de modo que su distribución tenga un valor medio de 0 y una desviación estándar de 1. 
*  En el caso de datos multivariados, esto se hace en función de las características.
"""

dfs_X.values
dfs_Y.values

scaler = StandardScaler()
inputs = scaler.fit_transform(dfs_X)
dX = np.array(inputs, dtype='float32')
dY = np.array(dfs_Y, dtype='float32')

dX

dY

"""**Verificar las dimenciones de muestras matrices a utilizar**"""

print('tamaño de dX INDICADORES : ',dX.shape) #tamaño de dX INDICADORES 
print('tamaño de dY ROE : ',dY.shape) #tamaño de dY ROE

X = torch.from_numpy(dX)
Y = torch.from_numpy(dY)

from torch.utils.data import TensorDataset
dataset = TensorDataset(X,Y)

dataset[1:2]

from torch.utils.data import DataLoader
bs=64
train_loader = DataLoader(dataset,batch_size=bs,shuffle=True)

"""**Análisis de datos que predice el valor de datos desconocidos mediante el uso de otro valor de datos relacionado y conocido.**"""

class ModeloRegresionLineal(torch.nn.Module):
  def __init__(self):
    super(ModeloRegresionLineal, self).__init__()
    self.linear = torch.nn.Linear(5,1)  #X @ w.t() + b

  def forward(self, x):
    y_pred = self.linear(x)
    return y_pred

"""**Epoch =** instante de tiempo considerado como punto de partida para un periodo o evento en particular.

**Ta =** Taza de Aprendizaje
"""

epochs = 30
ta = 1e-9 # Tasa Aprendizaje

modelo = ModeloRegresionLineal()
funcion_costo = torch.nn.MSELoss(reduction = 'mean')
optimizer = torch.optim.SGD(modelo.parameters(), lr = ta) #Actualiza los pesos w y el bias b 

for i in range(epochs):
  for x,y in train_loader:
    preds = modelo(x)
    loss = funcion_costo(preds, y)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
  print(f"Epoch {i}/{epochs}: Loss {loss}")

modelo.linear.weight #w

modelo.linear.bias #b

# Evaluando el modelo
y_pred = []
y_true = []
modelo.train(False)
for inputs, targets in train_loader:
  y_pred.extend(modelo(inputs).data.numpy())
  y_true.extend(targets.numpy())
plt.scatter(y_pred, y_true)
plt.ylabel('ROE')
plt.xlabel('ROE (Predicciones)')
plt.plot([-1,1], [-1, 1], '--k', c='r')
plt.show()
    # Calculando Errores
mae = mean_absolute_error(y_true=y_true, y_pred=y_pred)
mse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=True)
rmse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=False)
print(f"\nResultados Del año 2019 datos:")
print(f"MAE: {mae}")
print(f"MSE: {mse}")
print(f"RMSE: {rmse}")

"""A relación con nuestro trabajo anterios, en la gráfica ya nos permite mostrar mas datos, es por eso que se procedio a cambiar las varibles, lo cual nos permitio obtener un MAE bajo, por ende se puede decir que el modelo si esta **PREDICIENDO**

###**DESCRIPCIÓN CATEGORIAS - ROE**
"""

dfs_rg_l.plot.scatter(x='ROE',y= 'DESCRIPCIÓN RAMA', figsize=(20,30),title="CATEGORIAS - ROE")

import glob
import os

def Categoria_Lineal():


  categ =  dfs_rg_l[['RAMA']].values
  dfs_rg_l['RAMA'] = categ
  metrics = {"DESCRIPCIÓN": [], "MAE": [], "MSE": [], "RMSE": []}
  grouped =  dfs_rg_l.groupby("RAMA")
  for categoria, group in grouped:
      X_Lnl = group[['RENTABLIDAD FINANCIERA','RENTABILIDAD NETA DEL ACTIVO','UTILIDAD OPERACIONAL/TOTAL DE ACTIVOS ','ROTACIÓN DE VENTAS','ENDEUDAMIENTO PATRIMONIAL CORRIENTE']].values
      Y_Lnl = group[['ROE']].values
      # Escalando
      scaler = StandardScaler()
      inputs = scaler.fit_transform(X_Lnl)
      X_Lnl = torch.from_numpy(inputs.astype(np.float32))
      Y_Lnl = torch.from_numpy(Y_Lnl.astype(np.float32))
      dataset_test = TensorDataset(X_Lnl, Y_Lnl)
      test_loader = DataLoader(dataset_test, batch_size=bs, shuffle=True)
      # Evaluando el modelo
      y_pred = []
      y_true = []
      modelo.train(False)
      for inputs, targets in test_loader:
        y_pred.extend(modelo(inputs).data.numpy())
        y_true.extend(targets.numpy())
      # Calculando Errores
      mae = mean_absolute_error(y_true=y_true, y_pred=y_pred)
      mse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=True)
      rmse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=False)
      metrics["DESCRIPCIÓN"].append(categoria)
      metrics["MAE"].append(mae)
      metrics["MSE"].append(mse)
      metrics["RMSE"].append(rmse)
          
  metrics_df = pd.DataFrame(metrics)
  metrics_df = metrics_df.sort_values("MSE")
  print("LAS CATEGORIAS MAYORES ERRORES :")
  print(metrics_df.tail(8))
  print("LAS CATEGORIAS MENORES ERRORES :")
  print(metrics_df.head(8))

"""**Analsis de Errores relacionados a las Categorias del Dataset**"""

Categoria_Lineal()

"""##**PREDICCIÓN**

###**PREDICCIÓN 2017**

**Modelo Predictivo lineal del 2017**
"""

df_2017 = pd.read_csv('/content/drive/My Drive/ProyectoDatasets/indicadores2017.csv' )
#Remover Outliers
df_2017 = df_2017[(df_2017['ROE'] > -1) & (df_2017['ROE'] < 1) & (df_2017['RENTABLIDAD FINANCIERA'] < 100) & (df_2017['UTILIDAD OPERACIONAL/TOTAL DE ACTIVOS '] > -10) &
            (df_2017['RENTABILIDAD NETA DEL ACTIVO'] > -3) & (df_2017['ROTACIÓN DE VENTAS'] < 10) & (df_2017['ENDEUDAMIENTO PATRIMONIAL CORRIENTE'] < 400)]
dfsX_2017 = df_2017[[  'RENTABLIDAD FINANCIERA','RENTABILIDAD NETA DEL ACTIVO','UTILIDAD OPERACIONAL/TOTAL DE ACTIVOS ','ROTACIÓN DE VENTAS','ENDEUDAMIENTO PATRIMONIAL CORRIENTE']].values
dfsY_2017 = df_2017[['ROE']].values

scaler = StandardScaler()
inputs = scaler.fit_transform(dfsX_2017)
inputs_rl = np.array(inputs, dtype='float32')
dY_2017 = np.array(dfsY_2017, dtype='float32')
from torch.utils.data import TensorDataset
X_2017 = torch.from_numpy(inputs_rl)
Y_2017 = torch.from_numpy(dY_2017)
dataset_test = TensorDataset(X_2017, Y_2017)
test_loader = DataLoader(dataset_test, batch_size=bs, shuffle=True)
 # Evaluando el modelo
y_pred = []
y_true = []
modelo.train(False)
for inputs, targets in test_loader:
  y_pred.extend(modelo(inputs).data.numpy())
  y_true.extend(targets.numpy())
plt.scatter(y_pred, y_true)
plt.ylabel('ROE')
plt.xlabel('ROE (Predicciones)')
plt.plot([-1,1], [-1, 1], '--k', c='r')
plt.show()
    # Calculando Errores
mae = mean_absolute_error(y_true=y_true, y_pred=y_pred)
mse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=True)
rmse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=False)
print(f"\nResultados Del año 2017 datos:")
print(f"MAE: {mae}")
print(f"MSE: {mse}")
print(f"RMSE: {rmse}")

"""**Los Datos del MAE son inferiores a 1, lo que nos dice que el modelo si aprendio**"""

x_2017 = torch.from_numpy(np.array([[-0.183871,	-0.068310,	-0.102356,	-0.282979,	-0.038027]], 
  dtype='float32'))
y_2017 = modelo(x_2017) #predicción
print(y_2017)

x_2017 = torch.from_numpy(np.array([[dfsX_2017]], 
  dtype='float32'))
y_2017 = modelo(x_2017) #predicción
print('prediccion media : ',y_2017.mean())
print('prediccion maxima : ',y_2017.max())
print('prediccion minima : ',y_2017.min())

"""###**PREDICCIÓN 2018**"""

df_2018 = pd.read_csv('/content/drive/My Drive/ProyectoDatasets/indicadores2018.csv' )
#Remover Outliers
df_2018 =df_2018[(df_2018['ROE'] > -1) & (df_2018['ROE'] < 1) & (df_2018['RENTABLIDAD FINANCIERA'] < 100) & (df_2018['UTILIDAD OPERACIONAL/TOTAL DE ACTIVOS '] > -10) &
            (df_2018['RENTABILIDAD NETA DEL ACTIVO'] > -3) & (df_2018['ROTACIÓN DE VENTAS'] < 10) & (df_2018['ENDEUDAMIENTO PATRIMONIAL CORRIENTE'] < 400)]
dfsX_2018 = df_2018[[  'RENTABLIDAD FINANCIERA','RENTABILIDAD NETA DEL ACTIVO','UTILIDAD OPERACIONAL/TOTAL DE ACTIVOS ','ROTACIÓN DE VENTAS','ENDEUDAMIENTO PATRIMONIAL CORRIENTE']].values
dfsY_2018 = df_2018[['ROE']].values

scaler = StandardScaler()
inputs = scaler.fit_transform(dfsX_2018)
inputs_2018 = np.array(inputs, dtype='float32')
dY_2018 = np.array(dfsY_2018, dtype='float32')
from torch.utils.data import TensorDataset
X_2018 = torch.from_numpy(inputs_2018)
Y_2018 = torch.from_numpy(dY_2018)
dataset_test = TensorDataset(X_2018, Y_2018)
test_loader = DataLoader(dataset_test, batch_size=bs, shuffle=True)
 # Evaluando el modelo
y_pred = []
y_true = []
modelo.train(False)
for inputs, targets in test_loader:
  y_pred.extend(modelo(inputs).data.numpy())
  y_true.extend(targets.numpy())
plt.scatter(y_pred, y_true)
plt.ylabel('ROE')
plt.xlabel('ROE (Predicciones)')
plt.plot([-1,1], [-1, 1], '--k', c='r')
plt.show()
    # Calculando Errores
mae = mean_absolute_error(y_true=y_true, y_pred=y_pred)
mse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=True)
rmse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=False)
print(f"\nResultados Del año 2018 datos:")
print(f"MAE: {mae}")
print(f"MSE: {mse}")
print(f"RMSE: {rmse}")

x_2018 = torch.from_numpy(np.array([[-0.051793,	-0.046931,	-0.042815,	-0.111525,	-0.038796]], 
  dtype='float32'))
y_2018 = modelo(x_2018) #predicción
print(y_2018)

x_2018 = torch.from_numpy(np.array([[dfsX_2018]], 
  dtype='float32'))
y_2018 = modelo(x_2018) #predicción
print('prediccion media : ',y_2018.mean())
print('prediccion maxima : ',y_2018.max())
print('prediccion minima : ',y_2018.min())

"""###**PREDICCIÓN 2019**"""

x_2019 = torch.from_numpy(np.array([[-0.144397	,-0.030758,	-0.147701,	-0.053338	,-0.031462]], 
  dtype='float32'))
y_2019 = modelo(x_2019) #predicción
print(y_2019)

x_2019 = torch.from_numpy(np.array([[dX]], 
  dtype='float32'))
y_2019 = modelo(x_2019) #predicción
print(y_2019.mean())
print('prediccion media : ',y_2019.mean())
print('prediccion maxima : ',y_2019.max())
print('prediccion minima : ',y_2019.min())

"""###**PREDICCIÓN 2020**"""

df_2020 = pd.read_csv('/content/drive/My Drive/ProyectoDatasets/indicadores2020.csv' )
#Remover Outliers
df_2020 = df_2020[(df_2020['ROE'] > -1) & (df_2020['ROE'] < 1) & (df_2020['RENTABLIDAD FINANCIERA'] < 100) & (df_2020['UTILIDAD OPERACIONAL/TOTAL DE ACTIVOS '] > -10) &
            (df_2020['RENTABILIDAD NETA DEL ACTIVO'] > -3) & (df_2020['ROTACIÓN DE VENTAS'] < 10) & (df_2020['ENDEUDAMIENTO PATRIMONIAL CORRIENTE'] < 400)]
dfsX_2020 = df_2020[[  'RENTABLIDAD FINANCIERA','RENTABILIDAD NETA DEL ACTIVO','UTILIDAD OPERACIONAL/TOTAL DE ACTIVOS ','ROTACIÓN DE VENTAS','ENDEUDAMIENTO PATRIMONIAL CORRIENTE']].values
dfsY_2020 = df_2020[['ROE']].values

scaler = StandardScaler()
inputs = scaler.fit_transform(dfsX_2020)
inputs_2020 = np.array(inputs, dtype='float32')
dY_2020 = np.array(dfsY_2020, dtype='float32')
from torch.utils.data import TensorDataset
X_2020 = torch.from_numpy(inputs_2020)
Y_2020 = torch.from_numpy(dY_2020)
dataset_test = TensorDataset(X_2020, Y_2020)
test_loader = DataLoader(dataset_test, batch_size=bs, shuffle=True)
 # Evaluando el modelo
y_pred = []
y_true = []
modelo.train(False)
for inputs, targets in test_loader:
  y_pred.extend(modelo(inputs).data.numpy())
  y_true.extend(targets.numpy())
plt.scatter(y_pred, y_true)
plt.ylabel('ROE')
plt.xlabel('ROE (Predicciones)')
plt.plot([-1,1], [-1, 1], '--k', c='r')
plt.show()
    # Calculando errores
mae = mean_absolute_error(y_true=y_true, y_pred=y_pred)
mse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=True)
rmse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=False)
print(f"\nResultados Del año 2020 datos:")
print(f"MAE: {mae}")
print(f"MSE: {mse}")
print(f"RMSE: {rmse}")

x_2020 = torch.from_numpy(np.array([[0.056737,	0.049883,	-0.055170,	0.361231,	-0.048506]], 
  dtype='float32'))
y_2020 = modelo(x_2020) #predicción
print(y_2020)

x_2020 = torch.from_numpy(np.array([[dfsX_2020]], 
  dtype='float32'))
y_2020 = modelo(x_2020) #predicción
print('prediccion media : ',y_2020.mean())
print('prediccion maxima : ',y_2020.max())
print('prediccion minima : ',y_2020.min())

"""#**Modelo De Regresión Logística -- ROA**

**La regresión logística resulta útil para los casos en los que se desea predecir la presencia o ausencia de una característica o resultado según los valores de un conjunto de predictores.**
"""

dfs_Rg_Log =  df_indicadores2019[['ROA','DESCRIPCIÓN RAMA','RAMA','RENTABILIDAD NETA DEL ACTIVO','RENTABLIDAD FINANCIERA','RENTABILIDAD NETA DE VENTAS',	'ENDEUDAMIENTO A CORTO PLAZO','ROTACIÓN DE ACTIVO FIJO']]
#Remover Outliers
dfs_Rg_Log = dfs_Rg_Log[(dfs_Rg_Log['ROA'] > -1) & (dfs_Rg_Log['ROA'] < 1) & (dfs_Rg_Log['RENTABILIDAD NETA DEL ACTIVO'] < 500) & (dfs_Rg_Log['RENTABLIDAD FINANCIERA'] > -1) &
            (dfs_Rg_Log['ENDEUDAMIENTO A CORTO PLAZO'] > -5) & (dfs_Rg_Log['RENTABILIDAD NETA DE VENTAS'] < 150) & (dfs_Rg_Log['ROTACIÓN DE ACTIVO FIJO'] < 400)]
dfs_Rg_Log

df_X_Log = dfs_Rg_Log[[ 'RENTABILIDAD NETA DEL ACTIVO','RENTABLIDAD FINANCIERA','RENTABILIDAD NETA DE VENTAS',	'ENDEUDAMIENTO A CORTO PLAZO','ROTACIÓN DE ACTIVO FIJO']]
df_X_Log

dfs_Y_Log = dfs_Rg_Log[['ROA']]
dfs_Y_Log

dfs_Y_Log['ROA_DIS'] = pd.qcut(dfs_Y_Log['ROA'], 5, labels=False)
dfs_Y_Log['ROA_DESCRIPCION'] = pd.qcut(dfs_Y_Log['ROA_DIS'], 4, labels=["MALO","REGULAR", "BUENO", "EXCELENTE"])
dfs_Y_Log

df_Y_Log = dfs_Y_Log[['ROA_DIS']]
df_Y_Log

"""###**ENTRENAMIENTO - ROA**

**Graficas de los valores y rango de las varibeles "X"**
"""

df_X_Log.plot(subplots=True, layout=(-1,3), figsize=(30,10) )

plt.figure(figsize = (15,7))
ax =sns.boxplot(data = df_X_Log, orient="h")
ax.set(xscale="log")
plt.show()

dfs_Y_Log.plot(subplots=True, layout=(-1,3), figsize=(30,5) )

plt.figure(figsize = (15,7))
ax =sns.boxplot(data = dfs_Y_Log, orient="h")
ax.set(xscale="log")
plt.show()

dX_Log= np.array(df_X_Log, dtype='float32')
dY_Log= df_Y_Log['ROA_DIS'].values

print('tamaño de dX INDICADORES : ',dX_Log.shape) #tamaño de dX INDICADORES 
print('tamaño de dY ROE : ',dY_Log.shape) #tamaño de dY ROA

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(dX_Log,dY_Log,test_size = 0.25)

import sklearn
scaler = sklearn.preprocessing.StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.fit_transform(x_test)

import numpy as np
x_train = torch.from_numpy(x_train.astype(np.float32))
x_test = torch.from_numpy(x_test.astype(np.float32))
## describir nuevo paso - numero enteros 
y_train = torch.from_numpy(y_train.astype(np.int64))
y_test = torch.from_numpy(y_test.astype(np.int64))

class LR_Model(torch.nn.Module):
  def __init__(self, n_features):
    super(LR_Model,self).__init__()
    self.logt  = torch.nn.Linear(n_features, 5)
    self.softmax = torch.nn.Softmax(dim=1)

  def forward(self, x):
    y_hat = torch.sigmoid(self.logt(x)) #regresión logistica necesita la función sigmoid
    return y_hat

#función que visualiza la evolución de la perdida y la precisión en cada epoch
def plot_loss(epochs, loss, loss_test, acc):
  plt.figure(figsize=(20,10))
  xlim = len(loss)
  plt.plot(epochs,loss)
  plt.plot(epochs,loss_test)
  plt.plot(epochs,acc)
  plt.xlabel('Epochs')
  plt.ylabel('Value')
  plt.legend(('Train loss','Test loss','Accuracy'),loc='center right',shadow=True)
  plt.title('Train and Test Loss vs Accuracy')

#función que realiza el entrenamiento
def train(num_epochs, optimizer, cost, model):
  #listas usadas para guardar los valores de pérdida, precisión, para cada epoch
  #esta información sirve para graficar el proceso de entrenamiento
  loss_vals = []
  loss_test_vals = []
  acc_vals = []
  epoch_vals = []

  #entrenamiento
  for epoch in range(num_epochs):
    y_hat = model(x_train)
    loss = cost(y_hat,y_train)
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()

    #se evalua cada 5 epochs
    if (epoch+1)%4 == 0:
      with torch.no_grad():
        loss_vals.append(loss.item())
        y_hat_test = model(x_test)  #se usan los datos de prueba para evaluar el modelo
        loss_test = cost(y_hat_test, y_test)
        loss_test_vals.append(loss_test.item())
        y_hat_class = y_hat_test.argmax(dim=1) #se redondea para saber si la clase es 1 o 0, recordar que sigmoid devuelve valor entre 0 y 1
        accuracy = (y_hat_class.eq(y_test).sum())/float(y_hat_test.shape[0]) #se cuenta las correctas y se divide para el total de datos de prueba
        acc_vals.append(accuracy.item())
        epoch_vals.append(epoch)
      print(f'epoch:{epoch+1} loss={loss.item()} loss_test={loss_test.item()} accuracy={accuracy.item()}')
  plot_loss(epoch_vals,loss_vals,loss_test_vals,acc_vals)

print(x_train[1])
print(y_train[1])

n_features = dX.shape[1] #en este caso 30 features
lr_model = LR_Model(n_features)
costo =  torch.nn.CrossEntropyLoss()  
optim = torch.optim.Adam(lr_model.parameters(),lr=0.01) #gradiente descendente
train(num_epochs=300, optimizer=optim, cost=costo, model=lr_model)

print(x_test[1])

features = [0.98845005,  0.06927466,  0.0363    ,  0.07008413,  0.03588073]
y_prueba = lr_model(x_test)
etiquetas = y_prueba.argmax(dim=1)
print(etiquetas)

# Evaluando el modelo 2019
y_pred = []
y_true = []
modelo.train(False)
for inputs, targets in test_loader:
  y_pred.extend(modelo(inputs).data.numpy())
  y_true.extend(targets.numpy())
plt.scatter(y_pred, y_true)
plt.ylabel('ROA')
plt.xlabel('ROA (Predicciones)')
plt.plot([-1,1], [-1, 1], '--k', c='r')
plt.show()
    # Calculando Errores
mae = mean_absolute_error(y_true=y_true, y_pred=y_pred)
mse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=True)
rmse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=False)

print(f"\nResultados Del año 2019 datos:")
print(f"MAE: {mae}")
print(f"MSE: {mse}")
print('Accuracy: {:.2f}%'.format(mse*10))

"""###**DESCRIPCIÓN CATEGORIAS - ROA**"""

dfs_Rg_Log.plot.scatter(x='ROA',y= 'DESCRIPCIÓN RAMA', figsize=(20,30),title="CATEGORIAS - ROA")

import glob
import os
def Categoria_LOG():
  dfs_Rg_Log ['ROA_DIS'] = pd.qcut(dfs_Rg_Log['ROA'], 4, labels=False)
  categ =  dfs_Rg_Log[['RAMA']].values
  dfs_Rg_Log['RAMA'] = categ
  metrics = {"DESCRIPCIÓN": [],  "MSE": [], "RMSE": [],"ACC": []}
  grouped =  dfs_Rg_Log.groupby("RAMA")
  for categoria, group in grouped:
      X_rlg = group[['RENTABILIDAD NETA DEL ACTIVO','RENTABLIDAD FINANCIERA','RENTABILIDAD NETA DE VENTAS',	'ENDEUDAMIENTO A CORTO PLAZO','ROTACIÓN DE ACTIVO FIJO']].values
      Y_rlg = group[['ROA_DIS']].values
      # Escalando
      scaler = StandardScaler()
      inputs = scaler.fit_transform(X_rlg)
      X_rlg = torch.from_numpy(inputs.astype(np.float32))
      Y_rlg = torch.from_numpy(Y_rlg.astype(np.int64))
      dataset_test = TensorDataset(X_rlg, Y_rlg)
      test_loader = DataLoader(dataset_test, batch_size=bs, shuffle=True)
      # Evaluando el modelo
      y_pred = []
      y_true = []
      modelo.train(False)
      for inputs, targets in test_loader:
        y_hat_test = modelo(inputs).data.numpy()
        y_hat_class = np.argmax(y_hat_test, axis=1)
        y_pred.extend(y_hat_class)
        y_true.extend(targets.numpy())
      # Calculando Errores
      mse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=True)
      rmse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=False)
      acc = accuracy_score(y_true, y_pred)
      metrics["DESCRIPCIÓN"].append(categoria)
      metrics["MSE"].append(mse)
      metrics["RMSE"].append(rmse)
      metrics["ACC"].append(acc)
  metrics_df = pd.DataFrame(metrics)
  metrics_df = metrics_df.sort_values("MSE")
  print("LAS CATEGORIAS MAYORES ERRORES :")
  print(metrics_df.tail(8))
  print("LAS CATEGORIAS MENORES ERRORES :")
  print(metrics_df.head(8))

Categoria_LOG()

"""##**PREDICCIÓN - ROA**

###**PREDICCIÓN 2017**
"""

df_Log_2017 = pd.read_excel('/content/drive/My Drive/DataSets/indicadores2017_cia.xlsx' )
#Remover Outliers
df_Log_2017 = df_Log_2017[(df_Log_2017['ROA'] > -1) & (df_Log_2017['ROA'] < 1) & (df_Log_2017['RENTABILIDAD NETA DEL ACTIVO'] < 500) & (df_Log_2017['RENTABLIDAD FINANCIERA'] > -1) &
            (df_Log_2017['ENDEUDAMIENTO A CORTO PLAZO'] > -5) & (df_Log_2017['RENTABILIDAD NETA DE VENTAS'] < 150) & (df_Log_2017['ROTACIÓN DE ACTIVO FIJO'] < 400)]
            
dfsX_Log_2017 = df_Log_2017[['RENTABILIDAD NETA DEL ACTIVO','RENTABLIDAD FINANCIERA','RENTABILIDAD NETA DE VENTAS',	'ENDEUDAMIENTO A CORTO PLAZO','ROTACIÓN DE ACTIVO FIJO']].values
dfsY_Log_2017 = df_Log_2017[['ROA']]
dfsY_Log_2017['ROA_DIS'] = pd.qcut(dfsY_Log_2017['ROA'], 5, labels=False)
df_Y_Log_2017 = dfsY_Log_2017[['ROA_DIS']]

"""**Verificación de la Predicción de nuestro Modelo**"""

dX_Log_2017= np.array(dfsX_Log_2017, dtype='float32')
dY_Log_2017= df_Y_Log_2017['ROA_DIS'].values
x_train, x_test, y_train, y_test = train_test_split(dX_Log_2017,dY_Log_2017,test_size = 0.25)
# SCALER
scaler = sklearn.preprocessing.StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.fit_transform(x_test)
#
x_test_2017 = torch.from_numpy(x_test.astype(np.float32))
## describir nuevo paso - numero enteros 
y_test_2017 = torch.from_numpy(y_test.astype(np.int64))
dataset_test = TensorDataset(x_test_2017, y_test_2017)
test_loader = DataLoader(dataset_test, batch_size=bs, shuffle=True)

 # Evaluando el modelo
y_pred = []
y_true = []
modelo.train(False)
for inputs, targets in test_loader:
  y_pred.extend(modelo(inputs).data.numpy())
  y_true.extend(targets.numpy())
plt.scatter(y_pred, y_true)
plt.ylabel('ROA')
plt.xlabel('ROA (Predicciones)')
plt.plot([-1,1], [-1, 1], '--k', c='r')
plt.show()
    # Calculando Errores
mae = mean_absolute_error(y_true=y_true, y_pred=y_pred)
mse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=True)
rmse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=False)
print(f"\nResultados Del año 2017 datos:")
print(f"MAE: {mae}")
print(f"MSE: {mse}")
print('Accuracy: {:.2f}%'.format(mse*10))

X_LOG_2017 = torch.from_numpy(np.array([[0.247540,	0.026774,	0.067265,	0.823185,	0.016651]], 
  dtype='float32'))
Y_LOG_2017 = modelo(X_LOG_2017) #predicción
print(Y_LOG_2017)

y_prueba_2017 = lr_model(x_test_2017)
etiquetas_2017 = y_prueba_2017.argmax(dim=1)
print(etiquetas_2017)

x_LOG_2017 = torch.from_numpy(np.array([[dfsX_Log_2017]], 
  dtype='float32'))
y_LOG_2017 = modelo(x_LOG_2017) #predicción
print('prediccion media : ',y_LOG_2017.mean())
print('prediccion maxima : ',y_LOG_2017.max())
print('prediccion minima : ',y_LOG_2017.min())

"""###**PREDICCIÓN 2018**"""

df_Log_2018 = pd.read_excel('/content/drive/My Drive/DataSets/indicadores2018_cia.xlsx' )
#Remover Outliers
df_Log_2018 =  df_Log_2018[(df_Log_2018['ROA'] > -1) & (df_Log_2018['ROA'] < 1) & (df_Log_2018['RENTABILIDAD NETA DEL ACTIVO'] < 500) & (df_Log_2018['RENTABLIDAD FINANCIERA'] > -1) &
            (df_Log_2018['ENDEUDAMIENTO A CORTO PLAZO'] > -5) & (df_Log_2018['RENTABILIDAD NETA DE VENTAS'] < 150) & (df_Log_2018['ROTACIÓN DE ACTIVO FIJO'] < 400)]
dfsX_Log_2018 = df_Log_2018[['RENTABILIDAD NETA DEL ACTIVO','RENTABLIDAD FINANCIERA','RENTABILIDAD NETA DE VENTAS',	'ENDEUDAMIENTO A CORTO PLAZO','ROTACIÓN DE ACTIVO FIJO']]
dfsY_Log_2018 = df_Log_2018[['ROA']]
dfsY_Log_2018['ROA_DIS'] = pd.qcut(dfsY_Log_2018['ROA'], 5, labels=False)
df_Y_Log_2018 = dfsY_Log_2018[['ROA_DIS']]

"""**Verificación de la Predicción de nuestro Modelo**"""

dX_Log_2018= np.array(dfsX_Log_2018, dtype='float32')
dY_Log_2018= df_Y_Log_2018['ROA_DIS'].values
x_train, x_test, y_train, y_test = train_test_split(dX_Log_2018,dY_Log_2018,test_size = 0.25)
# SCALER
scaler = sklearn.preprocessing.StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.fit_transform(x_test)
#
x_test_2018 = torch.from_numpy(x_test.astype(np.float32))
y_test_2018 = torch.from_numpy(y_test.astype(np.int64))
dataset_test = TensorDataset(x_test_2018, y_test_2018)
test_loader = DataLoader(dataset_test, batch_size=bs, shuffle=True)

 # Evaluando el modelo
y_pred = []
y_true = []
modelo.train(False)
for inputs, targets in test_loader:
  y_pred.extend(modelo(inputs).data.numpy())
  y_true.extend(targets.numpy())
plt.scatter(y_pred, y_true)
plt.ylabel('ROA')
plt.xlabel('ROA (Predicciones)')
plt.plot([-1,1], [-1, 1], '--k', c='r')
plt.show()
    # Calculando Errores
mae = mean_absolute_error(y_true=y_true, y_pred=y_pred)
mse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=True)
rmse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=False)
print(f"\nResultados Del año 2018 datos:")
print(f"MAE: {mae}")
print(f"MSE: {mse}")
print('Accuracy: {:.2f}%'.format(mse*10))

X_LOG_2018 = torch.from_numpy(np.array([[0.215171,	-0.024060,	-0.134273,	0.702969,	-0.028892]], 
  dtype='float32'))
Y_LOG_2018 = modelo(X_LOG_2018) #predicción
print(Y_LOG_2018)

y_prueba_2018 = lr_model(x_test_2018)
etiquetas_2018 = y_prueba_2018.argmax(dim=1)
print(etiquetas_2018)

x_LOG_2018 = torch.from_numpy(np.array([[dfsX_Log_2018]], 
  dtype='float32'))
y_LOG_2018 = modelo(x_LOG_2018) #predicción
print('prediccion media : ',y_LOG_2018.mean())
print('prediccion maxima : ',y_LOG_2018.max())
print('prediccion minima : ',y_LOG_2018.min())

"""###**PREDICCIÓN 2019**"""

X_LOG_2019 = torch.from_numpy(np.array([[0.98845005,  0.06927466,  0.0363    ,  0.07008413,  0.03588073]], 
  dtype='float32'))
Y_LOG_2019 = modelo(X_LOG_2019) #predicción
print(Y_LOG_2019)

#y_prueba_2019 = lr_model(x_test)
#etiquetas_2019 = y_prueba_2019.argmax(dim=1)
#print(etiquetas_2019)

x_LOG_2019 = torch.from_numpy(np.array([[df_X_Log]], 
  dtype='float32'))
y_LOG_2019 = modelo(x_LOG_2019) #predicción
print('prediccion media : ',y_LOG_2019.mean())
print('prediccion maxima : ',y_LOG_2019.max())
print('prediccion minima : ',y_LOG_2019.min())

"""###**PREDICCIÓN 2020**"""

df_Log_2020 = pd.read_excel('/content/drive/My Drive/DataSets/indicadores2020_cia.xlsx' )
#Remover Outliers
df_Log_2020 = df_Log_2020[(df_Log_2018['ROA'] > -1) & (df_Log_2020['ROA'] < 1) & (df_Log_2018['RENTABILIDAD NETA DEL ACTIVO'] < 500) & (df_Log_2020['RENTABLIDAD FINANCIERA'] > -1) &
            (df_Log_2020['ENDEUDAMIENTO A CORTO PLAZO'] > -5) & (df_Log_2020['RENTABILIDAD NETA DE VENTAS'] < 150) & (df_Log_2020['ROTACIÓN DE ACTIVO FIJO'] < 400)]
dfsX_Log_2020 = df_Log_2020[['RENTABILIDAD NETA DEL ACTIVO','RENTABLIDAD FINANCIERA','RENTABILIDAD NETA DE VENTAS',	'ENDEUDAMIENTO A CORTO PLAZO','ROTACIÓN DE ACTIVO FIJO']].values
dfsY_Log_2020 = df_Log_2020[['ROA']]
dfsY_Log_2020['ROA_DIS'] = pd.qcut(dfsY_Log_2020['ROA'], 5, labels=False)
dfsY_Log_2020['ROA_DESCRIPCION'] = pd.qcut(dfsY_Log_2020['ROA_DIS'], 4, labels=["MALO","REGULAR", "BUENO", "EXCELENTE"])
df_Y_Log_2020 = dfsY_Log_2020[['ROA_DIS']]

"""**Verificación de la Predicción de nuestro Modelo**"""

dX_Log_2020= np.array(dfsX_Log_2020, dtype='float32')
dY_Log_2020= df_Y_Log_2020['ROA_DIS'].values
x_train, x_test, y_train, y_test = train_test_split(dX_Log_2020,dY_Log_2020,test_size = 0.25)
# SCALER
scaler = sklearn.preprocessing.StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.fit_transform(x_test)
#
x_test_2020 = torch.from_numpy(x_test.astype(np.float32))
y_test_2020 = torch.from_numpy(y_test.astype(np.int64))
dataset_test = TensorDataset(x_test_2020, y_test_2020)
test_loader = DataLoader(dataset_test, batch_size=bs, shuffle=True)

 # Evaluando el modelo
y_pred = []
y_true = []
modelo.train(False)
for inputs, targets in test_loader:
  y_pred.extend(modelo(inputs).data.numpy())
  y_true.extend(targets.numpy())
plt.scatter(y_pred, y_true)
plt.ylabel('ROA')
plt.xlabel('ROA (Predicciones)')
plt.plot([-1,1], [-1, 1], '--k', c='r')
plt.show()
    # Calculando Errores
mae = mean_absolute_error(y_true=y_true, y_pred=y_pred)
mse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=True)
rmse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=False)
print(f"\nResultados Del año 2020 datos:")
print(f"MAE: {mae}")
print(f"MSE: {mse}")
print('Accuracy: {:.2f}%'.format(mse*10))

X_LOG_2020 = torch.from_numpy(np.array([[0.215171,	-0.024060,	-0.134273,	0.702969,	-0.028892]], 
  dtype='float32'))
Y_LOG_2020 = modelo(X_LOG_2020) #predicción
print(Y_LOG_2020)

y_prueba_2020 = lr_model(x_test_2020)
etiquetas_2020 = y_prueba_2020.argmax(dim=1)
print(etiquetas_2020)

x_LOG_2020 = torch.from_numpy(np.array([[df_X_Log]], 
  dtype='float32'))
y_LOG_2020 = modelo(x_LOG_2020) #predicción
print('prediccion media : ',y_LOG_2020.mean())
print('prediccion maxima : ',y_LOG_2020.max())
print('prediccion minima : ',y_LOG_2020.min())

"""#**RESULTADOS PREDICCIONES ROE / ROA**

##**¿Qué Año Predice Mejor y Peor?**

###**RESULTADO - ROE**

####**TABLA RESULTADOS REGRESIÓN LINEAL**


```
 POR AÑO
```

Errores | 2017 | 2018 | 2019 | 2020 
--- | -------------- | ---------- | ---------- | ---------- 
MAE  |  0.2760            |   0.26559   | 0.38335    |  0.2580
MSE  |0.4885          |0.45953    | 0.461162   |0.4556
RMSE | 0.6989           |0.6778   | 0.679089  | 0.67502

---

Pred_Dist | 2017 | 2018 | 2019 | 2020 
--- | -------------- | ---------- | ---------- | ---------- 
ROE  | 0.05435            | 0.22508         | 0.39520         | 0.42733     

---

Pred_Min | 2017 | 2018 | 2019 | 2020 
--- | -------------- | ---------- | ---------- | ---------- 
ROE |-11.0781    |-13.5071  | -10.3494        | -18.409

---

Pred_Max | 2017 | 2018 | 2019 | 2020 
--- | -------------- | ---------- | ---------- | ---------- 
ROE    | 0.2195      |0.8323  | 8.8703        | 1.0710

---

Pred_Media | 2017 | 2018 | 2019 | 2020 
--- | -------------- | ---------- | ---------- | ---------- 
ROE      |-1.4840    |-1.4935     | -0.1251        | -1.3337

---

###**RESULTADO - ROA**

####**TABLA RESULTADOS REGRESIÓN LOGISTICA**

```
 POR AÑO
```


Errores | 2017 | 2018 | 2019 | 2020 
--- | -------------- | ---------- | ---------- | ---------- 
MAE  |  2.167            |  2.204         | 1.984        | 2.209
MSE  |6.450           |6.621         | 5.879        | 6.827
Accuracy | 64.50%           | 66.21%        | 58.79%       | 68.28%

---

Pred_Dist | 2017 | 2018 | 2019 | 2020 
--- | -------------- | ---------- | ---------- | ---------- 
ROA  | -0.0903            | 0.1727         | -0.1796        | -0.1727

---

Pred_Min | 2017 | 2018 | 2019 | 2020 
--- | -------------- | ---------- | ---------- | ---------- 
ROA  | -14.936           |  -13.164     |-13.771        | -13.77

---

Pred_Max | 2017 | 2018 | 2019 | 2020 
--- | -------------- | ---------- | ---------- | ---------- 
ROA  | 3.6393           | 4.1707         | 1.197       | 1.197

---

Pred_Media | 2017 | 2018 | 2019 | 2020 
--- | -------------- | ---------- | ---------- | ---------- 
ROA  |4.929           | 2.808         | 1.778       | 1.77

---

##**¿Qué categoría de empresas predice mejor y peor?**

###**RESULTADO - ROE**

####**TABLA RESULTADOS REGRESIÓN LINEAL - ROE**

```
 CATEGORIAS - RAMA - ROE
```

DESCRIPCIÓN |RAMA |  MAE |  MSE | RMSE   
--- | -------------- | ---------- | ----------| ----------  
MINAS Y CANTERAS|B  |0.486445  |0.393775 | 0.627515     
ARTES|R  | 0.481757  |0.459923  |0.678176 
AGRICULTURA |A |  0.501536  |0.556991  |0.746319   
ACTIVIDADES FINANCIERAS|K  | 0.562317  |0.531041  |0.728726
OTRAS ACTIVIDADES DE SERVICIOS |S | 0.539458  |0.572015 | 0.756317     
ACTIVIDADES INMOBILIARIAS|L  | 0.445892 | 0.438722|  0.662361
ENSEÑANZA. |P| 0.693323|  0.993659|  0.996824 
SERVICIOS ADMINISTRATIVOS|N   |  0.477971 | 0.510848|  0.714737
COMUNICACION|J  |   0.509812|  0.560664 | 0.748775
DIST AGUA ALCANTARILLADO|E |  0.416877  |0.443153|  0.665698   
TRANSPORTE |H |  0.461001  |0.466719  |0.683168
SALUD HUMANA  |Q| 0.509160|  0.502433|  0.708825  
INDUSTRIAS MANUFACTURERAS  |C |0.447776 | 0.483757 | 0.695526
ACTIVIDADES PROFESIONALES|M|0.501314 | 0.580471  |0.761886
SUMINISTRO DE ELECTRICIDAD|D  |0.494666|  0.481828  |0.694139
COMERCIO AL POR MAYOR	|G|0.459191|  0.488442|  0.698886

###**RESULTADO - ROA**

####**TABLA RESULTADOS REGRESIÓN LOGISTICA - ROA**

```
 CATEGORIAS - RAMA - ROA
```

DESCRIPCIÓN |RAMA |  MSE    |  RMSE    |   ACC  
--- | -------------- | ---------- | ----------| ----------  
MINAS Y CANTERAS|B  | 3.342342 | 1.828207  |0.252252     
ARTES|R  |3.108108 | 1.762983|  0.324324  
COMERCIO AL POR MAYOR|G | 3.491120 | 1.868454 | 0.234505
AGRICULTURA |A | 3.333333 | 1.825742 | 0.300000    
ACTIVIDADES FINANCIERAS|K  | 3.888889|  1.972027 | 0.074074
OTRAS ACTIVIDADES DE SERVICIOS |S | 4.775281  |2.185242|  0.168539  
SUMINISTRO DE ELECTRICIDAD|D  | 4.532258  |2.128910 | 0.177419     
ACTIVIDADES INMOBILIARIAS|L  | 3.039409 | 1.743390  |0.231527
ENSEÑANZA. |P| 4.029412|  2.007339 | 0.264706     
SERVICIOS ADMINISTRATIVOS|N   |  3.809969|  1.951914|  0.218069
COMUNICACION|J  | 3.909884|  1.977343 | 0.223837 
ACTIVIDADES PROFESIONALES|M  | 4.097122 | 2.024135 | 0.208633
SALUD HUMANA  |Q|4.110345|  2.027399 | 0.241379 
SERVICIO DE COMIDAS |I  |3.148454 | 1.774388 | 0.338144 
CONSTRUCCION |F  |3.314560  |1.820593 | 0.232143
INDUSTRIAS MANUFACTURERAS |C  | 3.379617  |1.838374  |0.276368

---

#**CONCLUSIÓN**

#**¿Qué año predice mejor y peor?**

    Podemos idenfiticar mediante el analisis que el año que precide Mejor / Peor en el ROE:

 *   En el ROE el mejor es el año 2018 ya que tiene una distancia predicción de solo  0.05435 en comparación de los otros años con un menor de error MAE: 0.45953
*   Su peor año 2020 ya que tiene una distancia predicción del mas elevado de 0.0.39520  con un mayor de error MAE: 0.4556


    Podemos idenfiticar mediante el analisis que el año que precide Mejor / Peor en el ROA:

 *   En el ROA el mejor es el año 2017 ya que tiene una distancia predicción de solo  0.1727 en comparación de los otros años con un error MAE:2.167,  Accuracy = 64.50%   

*   Su peor año 2020 ya que tiene una distancia predicción -0.1796 con un mayor de error MAE: 2.209, Accuracy = 68.28% 
_____________________________________________________________________________

#**¿Qué categoría de empresas predice mejor y peor?**

    Podemos idenfiticar mediante el analisis que la categoria que precide Mejor / Peor en el ROE:

*   En el ROE la categoria que predicen mejor y con menos errores son las empresas de dits agua alcantarillado  MSE =0.395359, artes MSE = 0.401511  , actividades de servicios MSE =  0.453657.
*   Con las peores empresas que predicen con un mayor error son las empresas de  agricultura MSE = 0.499137, servicio de comidas MSE =  0.522686 , transporte MSE = 0.433548


    Podemos idenfiticar mediante el analisis que la categoria que precide Mejor / Peor en el ROA:
*   En el ROA la categoria que predicen mejor y con menos errores son las empresas de actividades financieras ACC = 0.074074, servicios administrativos ACC = 0.218069 , comunicacion ACC = 0.223837
*   Con las peores empresas que predicen con un mayor error son las empresas de artes  ACC = 0.324324, servicio de comida ACC = 0.338144  ,agricultura ACC =  0.300000
"""